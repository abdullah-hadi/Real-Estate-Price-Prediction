{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit (windows store)"
  },
  "metadata": {
   "interpreter": {
    "hash": "66e320cbb5d03a6fe294563c37ff05f213ae25a6e07c9c1224ef2c9099ebf48a"
   }
  },
  "interpreter": {
   "hash": "a0f60346f356de9dcf82f59c1c5c0504288e011994613b5e87f4fd4ea095bad2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h2 style=\"color:orange\" >PROJECT-200: House price prediction using machine\n",
    "learning algorithm </h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "$\\color{cyan}{\\text{Data Collect and Cleaning}}$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library..\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Dataset_Bangadesh.csv\") #read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"area_type\"].value_counts() #getting info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.drop(['area_type','society','availability', 'balcony' ],axis='columns') #remove some unnessesary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum() #Null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1.dropna() #remove null value from dataset\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"size\"].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['bhk'] = df2['size'].apply(lambda x : int(x.split(' ')[0])) #integer only column for BHK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['bhk'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.bhk > 20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.total_sqft.unique() #checking incorrect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "    except:\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[~df2['total_sqft'].apply(is_float)].head(15) #check inconsistent data in 'total_sqft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sqft_to_num(x) :\n",
    "    tokens = x.split('-')\n",
    "    if len(tokens) == 2 :\n",
    "        return (float(tokens[0]) + float(tokens[1]))/2\n",
    "    try :\n",
    "        return float(x)\n",
    "    except :\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2\n",
    "df3['total_sqft'] = df3['total_sqft'].apply(convert_sqft_to_num) # making consistent\n",
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3\n",
    "df4['price_per_sqft'] = df4['price']*100000/df4['total_sqft'] #create new column and count price per squarefeet\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df4.location.unique()) #location number check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.location = df4.location.apply(lambda x : x.strip()) #cleaning entries\n",
    "location_state=df4[\"location\"].value_counts() \n",
    "location_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(location_state[location_state <= 10]) #number of occurrences <=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_state_less_then_10 = location_state[location_state <= 10] #save smaller occurrences\n",
    "location_state_less_then_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df4.location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename location name(less then 10) to 'other'\n",
    "df4.location = df4.location.apply(lambda x: 'other' if x in location_state_less_then_10 else x)\n",
    "len(df4.location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "source": [
    "$\\color{cyan}{\\text{Removing Outliers}}$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[df4.total_sqft/df4.bhk < 300].head() #sqft per bhk(less then 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove some location(bhk < 300)\n",
    "df5 = df4[~(df4.total_sqft/df4.bhk < 300)]\n",
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.price_per_sqft.describe() #check price per sqft range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove very high or very low properties(price per sqft)\n",
    "def rmv_pps_outlier(df) :\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby('location') :\n",
    "        m = np.mean(subdf.price_per_sqft)\n",
    "        st = np.std(subdf.price_per_sqft)\n",
    "        reduce_df = subdf[(subdf.price_per_sqft > (m - st)) & (subdf.price_per_sqft <= (m+st))]\n",
    "        df_out = pd.concat([df_out, reduce_df], ignore_index=True)\n",
    "    return df_out\n",
    "df6 = rmv_pps_outlier(df5)\n",
    "df6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check pricing abnormalities\n",
    "def scatter(df, location) :\n",
    "    bhk2 = df[(df.location == location) & (df.bhk == 2)]\n",
    "    bhk3 = df[(df.location == location) & (df.bhk == 3)]\n",
    "    matplotlib.rcParams['figure.figsize'] = (15, 10)\n",
    "    plt.scatter(bhk2.total_sqft, bhk2.price, color = 'blue', label = '2 BHK', s = 50)\n",
    "    plt.scatter(bhk3.total_sqft, bhk3.price, color = 'green', marker = '+', label = '3 BHK', s = 50)\n",
    "    plt.xlabel('Total Square Feet Area')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(location)\n",
    "    plt.legend()\n",
    "scatter(df6, 'Alikadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove abnormalities\n",
    "def rmv_bhk_outlier(df) :\n",
    "    exclude_indices = np.array([])\n",
    "    for location, location_df in df.groupby('location') :\n",
    "        bhk_stats = {}\n",
    "        for bhk, bhk_df in location_df.groupby('bhk') :\n",
    "            bhk_stats[bhk] = {\n",
    "                'mean' : np.mean(bhk_df.price_per_sqft),\n",
    "                'std' : np.std(bhk_df.price_per_sqft),\n",
    "                'count' : bhk_df.shape[0]\n",
    "            }\n",
    "        for bhk, bhk_df in location_df.groupby('bhk') :\n",
    "            stats = bhk_stats.get(bhk-1)\n",
    "            if stats and stats['count'] > 5 :\n",
    "                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft < (stats['mean'])].index.values)\n",
    "    return df.drop(exclude_indices, axis = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = rmv_bhk_outlier(df6)\n",
    "df7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(df7, 'Alikadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking distribution\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 10)\n",
    "plt.hist(df7.price_per_sqft, rwidth = 0.8)\n",
    "plt.xlabel('Price Per Square Feet')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.bath.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7[df7.bath > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df7.bath,rwidth=0.8)\n",
    "plt.xlabel(\"Number of bathrooms\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing excess bathrooms\n",
    "df7[df7.bath > df7.bhk+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing excess bathrooms\n",
    "df8 = df7[df7.bath < df7.bhk+2]\n",
    "df8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unnecessary column \n",
    "df9 = df8.drop(['size', 'price_per_sqft'], axis = 'columns')\n",
    "df9.head(3)"
   ]
  },
  {
   "source": [
    "$\\color{cyan}{\\text{Machine Learning Model Building}}$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumies = pd.get_dummies(df9.location)\n",
    "dumies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = pd.concat([df9, dumies.drop('other', axis='columns')], axis = 'columns')\n",
    "df10.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df10.drop('location', axis = 'columns')\n",
    "df11.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df11.drop(['price'], axis = 'columns')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df11.price\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_clf = LinearRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "cross_val_score(LinearRegression(), X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "def find_best_model_using_gridsearchcv(X,y):\n",
    "    algos={\n",
    "        'linear_regression':{\n",
    "            'model':LinearRegression(),\n",
    "            'params':{\n",
    "                'normalize':[True, False]\n",
    "                }\n",
    "        },\n",
    "        'lasso':{\n",
    "            'model':Lasso(),\n",
    "            'params':{\n",
    "                'alpha':[1,2],\n",
    "                'selection':['random', 'cyclic']\n",
    "            }\n",
    "        },\n",
    "        'decision_tree':{\n",
    "            'model':DecisionTreeRegressor(),\n",
    "            'params':{\n",
    "                'criterion' :['mse','friedman_mse'],\n",
    "                'splitter':['best','random']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    scores =[]\n",
    "    cv=ShuffleSplit(n_splits=5,test_size=0.2,random_state=0)\n",
    "    for algo_name, config in algos.items():\n",
    "        gs = GridSearchCV(config['model'],config['params'],cv=cv,return_train_score=False)\n",
    "        gs.fit(X,y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "            })\n",
    "    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "find_best_model_using_gridsearchcv(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_price(location,sqft,bath,bhk):    \n",
    "    loc_index=np.where(X.columns==location)[0][0]\n",
    "    x=np.zeros(len(X.columns))\n",
    "    x[0]=sqft\n",
    "    x[1]=bath\n",
    "    x[2]=bhk\n",
    "    if loc_index >= 0:\n",
    "        x[loc_index] = 1\n",
    "    return lr_clf.predict([x])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price('Kishoreganj', 1600, 3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"Bangladesh_home_price.pickle\",\"wb\") as f:\n",
    "    pickle.dump(lr_clf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "columns={\n",
    "    \"data_columns\": [col.lower() for col in X.columns]\n",
    "}\n",
    "with open(\"columns.json\",\"w\") as f:\n",
    "    f.write(json.dumps(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}